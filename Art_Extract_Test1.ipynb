{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "95dcf502-788e-4a17-89a1-818504b84dd8",
   "metadata": {
    "id": "95dcf502-788e-4a17-89a1-818504b84dd8"
   },
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import layers, models, losses, optimizers, applications, mixed_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7cc38008-bdaa-4cf1-8cac-dfe8157af354",
   "metadata": {
    "id": "7cc38008-bdaa-4cf1-8cac-dfe8157af354"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "NUM_EPOCHS = 7  # Increase epochs when in production\n",
    "LEARNING_RATE = 0.001\n",
    "TASK = \"style\"  # Options: \"style\", \"artist\", \"genre\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f59553fc-c0f8-4e31-8b4f-b5dcdb55f045",
   "metadata": {
    "id": "f59553fc-c0f8-4e31-8b4f-b5dcdb55f045"
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_DIR = \"C:/Users/Ace/Gsoc_HumanAI/wikiart_csv\"\n",
    "WIKIART_DIR = \"C:/Users/Ace/Gsoc_HumanAI/wikiart\" # artwork images here\n",
    "MODELS_DIR = \"C:/Users/Ace/Gsoc_HumanAI\"\n",
    "TRAIN_DATA_PATH = f\"{BASE_DIR}/{TASK}_train.csv\"\n",
    "VAL_DATA_PATH = f\"{BASE_DIR}/{TASK}_val.csv\"\n",
    "CLASSES_PATH = f\"{BASE_DIR}/{TASK}_class.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cd69abd5-4847-487c-9008-1fe13fc5acd2",
   "metadata": {
    "id": "cd69abd5-4847-487c-9008-1fe13fc5acd2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def load_data(data_path, subset_size=1.0, random_state=42):\n",
    "    \"\"\"Load data from CSV file and apply stratified sampling.\"\"\"\n",
    "    df = pd.read_csv(data_path)\n",
    "    df.columns = ['image_path', 'label']\n",
    "\n",
    "    df['image_path'] = df['image_path'].apply(lambda x: os.path.join(WIKIART_DIR, x))\n",
    "\n",
    "    df = df[df['image_path'].apply(os.path.exists)]\n",
    "\n",
    "    if subset_size < 1.0:\n",
    "        df = df.groupby('label', group_keys=False).apply(\n",
    "            lambda x: x.sample(frac=subset_size, random_state=random_state)\n",
    "        )\n",
    "\n",
    "    # Print sample paths for verification\n",
    "    sample_paths = df['image_path'].sample(min(5, len(df))).tolist()\n",
    "    for path in sample_paths:\n",
    "        print(f\"Checking if path exists: {path}\")\n",
    "        print(f\"Exists: {os.path.exists(path)}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_classes(classes_path):\n",
    "    \"\"\"Load class names from text file.\"\"\"\n",
    "    with open(classes_path, 'r') as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ec8be9ba-62c3-458e-b9eb-c4f01a72b386",
   "metadata": {
    "id": "ec8be9ba-62c3-458e-b9eb-c4f01a72b386"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(train_df, val_df, classes):\n",
    "    \"\"\"Preprocess data for training.\"\"\"\n",
    "    is_numeric_labels = isinstance(train_df['label'].iloc[0], (int, np.integer))\n",
    "\n",
    "    if is_numeric_labels:\n",
    "        train_df['label_encoded'] = train_df['label']\n",
    "        val_df['label_encoded'] = val_df['label']\n",
    "\n",
    "        label_map = {i: class_name for i, class_name in enumerate(classes)}\n",
    "\n",
    "        train_df['label_name'] = train_df['label'].map(label_map)\n",
    "        val_df['label_name'] = val_df['label'].map(label_map)\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        le.fit(classes)\n",
    "    else:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(classes)\n",
    "\n",
    "        unknown_train_labels = set(train_df['label']) - set(classes)\n",
    "        unknown_val_labels = set(val_df['label']) - set(classes)\n",
    "\n",
    "        if unknown_train_labels:\n",
    "            print(f\"Warning: Found {len(unknown_train_labels)} unknown labels in training data\")\n",
    "            print(f\"Sample unknown labels: {list(unknown_train_labels)[:5]}\")\n",
    "\n",
    "            train_df = train_df[train_df['label'].isin(classes)]\n",
    "\n",
    "        if unknown_val_labels:\n",
    "            print(f\"Warning: Found {len(unknown_val_labels)} unknown labels in validation data\")\n",
    "            print(f\"Sample unknown labels: {list(unknown_val_labels)[:5]}\")\n",
    "\n",
    "            val_df = val_df[val_df['label'].isin(classes)]\n",
    "\n",
    "        train_df['label_encoded'] = le.transform(train_df['label'])\n",
    "        val_df['label_encoded'] = le.transform(val_df['label'])\n",
    "\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(train_df['label_encoded']),\n",
    "        y=train_df['label_encoded']\n",
    "    )\n",
    "    class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "    return train_df, val_df, le, class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f4db0228-c20e-4f4d-83d9-553e0aebed25",
   "metadata": {
    "id": "f4db0228-c20e-4f4d-83d9-553e0aebed25"
   },
   "outputs": [],
   "source": [
    "def create_data_generators(df, batch_size, task):\n",
    "    \"\"\"Create a tf.data.Dataset compatible with EfficientNetB3.\"\"\"\n",
    "    def load_and_preprocess_image(path):\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "        image = tf.keras.applications.efficientnet.preprocess_input(image)\n",
    "        return image\n",
    "\n",
    "    def augment_image(image, label):\n",
    "        if task == \"style\":\n",
    "            image = tf.cast(image, tf.uint8)\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "            \n",
    "            image = tf.image.random_brightness(image, max_delta=0.1)  \n",
    "            image = tf.image.random_contrast(image, lower=0.9, upper=1.1) \n",
    "            image = tf.image.random_saturation(image, lower=0.9, upper=1.1)  \n",
    "            \n",
    "            crop_factor = tf.random.uniform([], 0.9, 1.0)  \n",
    "            crop_size = tf.cast(\n",
    "                tf.cast([IMG_HEIGHT, IMG_WIDTH], tf.float32) * crop_factor,\n",
    "                tf.int32\n",
    "            )\n",
    "            crop_size = tf.minimum(crop_size, [IMG_HEIGHT, IMG_WIDTH])\n",
    "            image = tf.image.random_crop(image, [crop_size[0], crop_size[1], 3])\n",
    "            image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "\n",
    "        elif task == \"artist\":\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "            image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "            image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "            image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
    "\n",
    "        elif task == \"genre\":\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "            \n",
    "            image = tf.image.random_brightness(image, max_delta=0.1)  \n",
    "            image = tf.image.random_contrast(image, lower=0.9, upper=1.1) \n",
    "            image = tf.image.random_saturation(image, lower=0.9, upper=1.1) \n",
    "            \n",
    "            if tf.random.uniform([], 0, 1) > 0.5:\n",
    "                crop_factor = tf.random.uniform([], 0.95, 1.0)  \n",
    "                crop_size = tf.cast(\n",
    "                    tf.cast([IMG_HEIGHT, IMG_WIDTH], tf.float32) * crop_factor,\n",
    "                    tf.int32\n",
    "                )\n",
    "                image = tf.image.random_crop(image, [crop_size[0], crop_size[1], 3])\n",
    "                image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    paths = df['image_path'].values\n",
    "    labels = df['label_encoded'].values\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        lambda path, label: (load_and_preprocess_image(path), label),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    dataset = dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1f4aca76-1efe-4910-a854-1baaa3645b1f",
   "metadata": {
    "id": "1f4aca76-1efe-4910-a854-1baaa3645b1f"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        y_true = tf.one_hot(tf.cast(y_true, tf.int32), tf.shape(y_pred)[-1])\n",
    "        alpha_t = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
    "        loss = -alpha_t * (y_true * tf.math.pow(1. - y_pred, gamma) * tf.math.log(y_pred))\n",
    "        return tf.reduce_sum(loss, axis=-1)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "class CosineAnnealingWithRestarts(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, initial_lr, T_max, eta_min=0):\n",
    "        self.initial_lr = initial_lr\n",
    "        self.T_max = T_max\n",
    "        self.eta_min = eta_min\n",
    "        self.t = 0\n",
    "\n",
    "    def __call__(self, step):\n",
    "        cos_inner = tf.math.pi * (self.t % self.T_max) / self.T_max\n",
    "        lr = self.eta_min + (self.initial_lr - self.eta_min) * (1 + tf.math.cos(cos_inner)) / 2\n",
    "        self.t += 1\n",
    "        return lr\n",
    "\n",
    "def build_conv_recurrent_model(num_classes, task, img_height=224, img_width=224):\n",
    "    \"\"\"Build improved models for art classification with fixes for artist task.\"\"\"\n",
    "    if task == \"style\" or task == \"genre\":\n",
    "        base_model = tf.keras.applications.EfficientNetB2(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(img_height, img_width, 3)\n",
    "        )\n",
    "    else:\n",
    "        base_model = tf.keras.applications.EfficientNetB2(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(img_height, img_width, 3)\n",
    "        )\n",
    "    \n",
    "    if task == \"style\":\n",
    "        for layer in base_model.layers[:-30]:\n",
    "            layer.trainable = False\n",
    "    elif task == \"genre\":\n",
    "        for layer in base_model.layers[:-60]:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        for layer in base_model.layers[:-40]:\n",
    "            layer.trainable = False\n",
    "    \n",
    "    inputs = Input(shape=(img_height, img_width, 3))\n",
    "    x = tf.keras.applications.efficientnet.preprocess_input(inputs)\n",
    "    x = base_model(x)\n",
    "\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    if task == \"artist\":\n",
    "        x = Dense(1536, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.4)(x)\n",
    "\n",
    "        shortcut =Dense(768)(x)\n",
    "        \n",
    "        x = Dense(768, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        \n",
    "        se = Dense(128, activation='relu')(x)\n",
    "        se = Dense(768, activation='sigmoid')(se)\n",
    "        x = x * se\n",
    "        \n",
    "        x = x + shortcut\n",
    "    \n",
    "    elif task == \"style\":\n",
    "        x = Dense(1024, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        \n",
    "        x = Dense(512, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        \n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "    \n",
    "    elif task == \"genre\":\n",
    "        x = Dense(1024, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        \n",
    "        x = Dense(512, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "    \n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    if task == \"style\":\n",
    "        optimizer = Adam(learning_rate=CosineAnnealingWithRestarts(2e-3, 1000), weight_decay=1e-5)\n",
    "    elif task == \"genre\":\n",
    "        initial_learning_rate = 5e-4\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate,\n",
    "            decay_steps=2000,\n",
    "            decay_rate=0.95,\n",
    "            staircase=True\n",
    "        )\n",
    "        optimizer = Adam(learning_rate=lr_schedule, weight_decay=1e-5)\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=CosineAnnealingWithRestarts(5e-4, 2000), weight_decay=1e-5)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=focal_loss(gamma=2.0, alpha=0.25),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1347a344-64bf-4a54-bbf0-6aedd4348047",
   "metadata": {
    "id": "1347a344-64bf-4a54-bbf0-6aedd4348047"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "def evaluate_model(model, val_dataset, le,TASK):\n",
    "    \"\"\"Evaluate the model and handle both integer and one-hot encoded labels.\"\"\"\n",
    "    # Create results folder\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    \n",
    "    plot_model(\n",
    "        model, \n",
    "        to_file=f'results/model_architecture_{TASK}.png', \n",
    "        show_shapes=True, \n",
    "        show_layer_names=True,\n",
    "        expand_nested=True\n",
    "    )\n",
    "    print(f\"Model architecture saved as 'results/model_architecture_{TASK}.png'\")\n",
    "\n",
    "    predictions = model.predict(val_dataset, steps=len(val_dataset), verbose=1)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "    true_classes = []\n",
    "    for _, labels in val_dataset:\n",
    "        labels = labels.numpy()\n",
    "        if labels.ndim == 2:\n",
    "            true_classes.extend(np.argmax(labels, axis=1))\n",
    "        else:\n",
    "            true_classes.extend(labels)\n",
    "\n",
    "    true_classes = np.array(true_classes)\n",
    "\n",
    "    accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "    f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\\n\")\n",
    "\n",
    "    conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "    class_report = classification_report(true_classes, predicted_classes, target_names=le.classes_)\n",
    "\n",
    "\n",
    "    with open(f'results/classification_report_{TASK}.txt', 'w') as f:\n",
    "        f.write(class_report)\n",
    "\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=le.classes_, yticklabels=le.classes_,\n",
    "                cbar_kws={'shrink': 0.8}, linewidths=0.5, linecolor='gray',\n",
    "                annot_kws={\"size\": 7},\n",
    "                vmin=0, vmax=conf_matrix.max()) \n",
    "\n",
    "    plt.title(f'Confusion Matrix for {TASK}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "\n",
    "    plt.xticks(ticks=np.arange(len(le.classes_)) + 0.5, labels=le.classes_, rotation=45, ha='right', fontsize=8)\n",
    "    plt.yticks(ticks=np.arange(len(le.classes_)) + 0.5, labels=le.classes_, rotation=0, va='center', fontsize=8)\n",
    "\n",
    "    plt.subplots_adjust(left=0.3, bottom=0.2) \n",
    "    \n",
    "    plt.savefig(f'results/confusion_matrix_{TASK}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    f1_scores = f1_score(true_classes, predicted_classes, average=None)\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    sns.barplot(x=le.classes_, y=f1_scores, palette='viridis')\n",
    "    \n",
    "    plt.title(f'Per-Class F1 Scores for {TASK}')\n",
    "    plt.ylabel('F1 Score')\n",
    "\n",
    "    plt.xticks(ticks=np.arange(len(le.classes_)), labels=le.classes_, rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/f1_scores_{TASK}.png')\n",
    "    plt.show()\n",
    "\n",
    "    with open(f'results/class_accuracy_{TASK}.txt', 'w') as f:\n",
    "        f.write(\"Class-wise Evaluation:\\n\")\n",
    "        for i, class_name in enumerate(le.classes_):\n",
    "            class_acc = conf_matrix[i, i] / conf_matrix[i].sum() if conf_matrix[i].sum() > 0 else 0\n",
    "            f.write(f\"{class_name} - Accuracy: {class_acc:.4f}\\n\")\n",
    "            \n",
    "    prediction_confidence = np.max(predictions, axis=1)\n",
    "    low_confidence_indices = np.where(prediction_confidence < 0.5)[0]\n",
    "    misclassified_indices = np.where(predicted_classes != true_classes)[0]\n",
    "    outlier_indices = np.union1d(low_confidence_indices, misclassified_indices)\n",
    "\n",
    "    print(f\"\\nFound {len(outlier_indices)} potential outliers\")\n",
    "\n",
    "    return outlier_indices, predictions, true_classes, predicted_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8107f2bc-abcc-40a9-bb92-4c058488dfdf",
   "metadata": {
    "id": "8107f2bc-abcc-40a9-bb92-4c058488dfdf"
   },
   "outputs": [],
   "source": [
    "def visualize_training_history(history,TASK):\n",
    "    \"\"\"Visualize training history\"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'training_history_{TASK}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def visualize_outliers(outlier_indices, val_dataset, predictions, true_classes, predicted_classes, le, task, num_examples=5):\n",
    "    \"\"\"Visualize outlier examples\"\"\"\n",
    "    \n",
    "    results_dir = f'results/{task}'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    images = []\n",
    "    for img_batch, _ in val_dataset:\n",
    "        images.extend(img_batch.numpy()) \n",
    "\n",
    "    if len(outlier_indices) > num_examples:\n",
    "        sample_indices = np.random.choice(outlier_indices, num_examples, replace=False)\n",
    "    else:\n",
    "        sample_indices = outlier_indices\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        if idx < len(images):  \n",
    "            image = images[idx]\n",
    "\n",
    "            if image.max() <= 1.0:  \n",
    "                image = (image * 255).astype('uint8')\n",
    "            else:\n",
    "                image = np.clip(image, 0, 255).astype('uint8')\n",
    "\n",
    "            true_label = le.classes_[true_classes[idx]]\n",
    "            pred_label = le.classes_[predicted_classes[idx]]\n",
    "            confidence = predictions[idx][predicted_classes[idx]]\n",
    "\n",
    "            plt.subplot(3, 2, i + 1)\n",
    "            plt.imshow(image)\n",
    "            plt.title(f\"True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.2f}\", fontsize=10)\n",
    "            plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    outlier_path = os.path.join(results_dir, f'outliers_{task}.png')\n",
    "    plt.savefig(outlier_path)\n",
    "    plt.show()\n",
    "    print(f\"Outliers saved to: {outlier_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3e4ea27d-4fef-4204-ba5d-449434131996",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e4ea27d-4fef-4204-ba5d-449434131996",
    "outputId": "61a97392-08fb-4793-a9e1-1c065a2ef35f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring dataset structure...\n",
      "\n",
      "========================================\n",
      "Exploring ARTIST dataset\n",
      "========================================\n",
      "Train file exists: True\n",
      "Val file exists: True\n",
      "Class file exists: True\n",
      "\n",
      "Train data shape: (13345, 2)\n",
      "Validation data shape: (5705, 2)\n",
      "\n",
      "Train columns: ['Realism/vincent-van-gogh_pine-trees-in-the-fen-1884.jpg', '22']\n",
      "\n",
      "Sample train data (first 3 rows):\n",
      "  Realism/vincent-van-gogh_pine-trees-in-the-fen-1884.jpg  22\n",
      "0  Baroque/rembrandt_the-angel-appearing-to-the-s...       20\n",
      "1  Post_Impressionism/paul-cezanne_portrait-of-th...       16\n",
      "2  Impressionism/pierre-auguste-renoir_young-girl...       17\n",
      "\n",
      "Number of unique labels in training data: 23\n",
      "Sample labels: [20, 16, 17, 9, 1]\n",
      "\n",
      "Sample image paths:\n",
      "  Romanticism/gustave-dore_paradise-lost-4.jpg\n",
      "  Exists in wikiart folder: True\n",
      "  Post_Impressionism/vincent-van-gogh_the-raising-of-lazarus-1890.jpg\n",
      "  Exists in wikiart folder: True\n",
      "  Impressionism/eugene-boudin_the-port-of-deauville-1.jpg\n",
      "  Exists in wikiart folder: True\n",
      "\n",
      "========================================\n",
      "Exploring GENRE dataset\n",
      "========================================\n",
      "Train file exists: True\n",
      "Val file exists: True\n",
      "Class file exists: True\n",
      "\n",
      "Train data shape: (45502, 2)\n",
      "Validation data shape: (19491, 2)\n",
      "\n",
      "Train columns: ['Northern_Renaissance/hieronymus-bosch_st-jacques-and-the-magician-hermogenes.jpg', '7']\n",
      "\n",
      "Sample train data (first 3 rows):\n",
      "  Northern_Renaissance/hieronymus-bosch_st-jacques-and-the-magician-hermogenes.jpg  \\\n",
      "0  Post_Impressionism/vincent-van-gogh_ears-of-wh...                                 \n",
      "1  Symbolism/theodor-severin-kittelsen_kvitebj-rn...                                 \n",
      "2  Expressionism/martiros-saryan_mother-of-the-ar...                                 \n",
      "\n",
      "   7  \n",
      "0  4  \n",
      "1  3  \n",
      "2  6  \n",
      "\n",
      "Number of unique labels in training data: 10\n",
      "Sample labels: [4, 3, 6, 8, 0]\n",
      "\n",
      "Sample image paths:\n",
      "  Post_Impressionism/wassily-kandinsky_gabriele-munter-1905.jpg\n",
      "  Exists in wikiart folder: True\n",
      "  Impressionism/childe-hassam_clarissa.jpg\n",
      "  Exists in wikiart folder: True\n",
      "  Post_Impressionism/pyotr-konchalovsky_pine-tree-1921.jpg\n",
      "  Exists in wikiart folder: True\n",
      "\n",
      "========================================\n",
      "Exploring STYLE dataset\n",
      "========================================\n",
      "Train file exists: True\n",
      "Val file exists: True\n",
      "Class file exists: True\n",
      "\n",
      "Train data shape: (57024, 2)\n",
      "Validation data shape: (24420, 2)\n",
      "\n",
      "Train columns: ['Impressionism/edgar-degas_landscape-on-the-orne.jpg', '12']\n",
      "\n",
      "Sample train data (first 3 rows):\n",
      "  Impressionism/edgar-degas_landscape-on-the-orne.jpg  12\n",
      "0         Realism/camille-corot_mantes-cathedral.jpg   21\n",
      "1  Abstract_Expressionism/gene-davis_untitled-197...    0\n",
      "2      Symbolism/kuzma-petrov-vodkin_in-the-1920.jpg   24\n",
      "\n",
      "Number of unique labels in training data: 27\n",
      "Sample labels: [21, 0, 24, 12, 7]\n",
      "\n",
      "Sample image paths:\n",
      "  Art_Nouveau_Modern/felix-vallotton_portrait-of-belgian-symbolist-poet-max-elskamp-1898.jpg\n",
      "  Exists in wikiart folder: True\n",
      "  Impressionism/edmund-charles-tarbell_the-bath-1893.jpg\n",
      "  Exists in wikiart folder: True\n",
      "  Impressionism/pierre-auguste-renoir_rocks-with-shrimp-fishermen-1892.jpg\n",
      "  Exists in wikiart folder: True\n",
      "\n",
      "Starting model training...\n"
     ]
    }
   ],
   "source": [
    "# Data exploration function\n",
    "def explore_dataset():\n",
    "    \"\"\"Explore the dataset structure\"\"\"\n",
    "    for task in [\"artist\", \"genre\", \"style\"]:\n",
    "        train_path = f\"{BASE_DIR}/{task}_train.csv\"\n",
    "        val_path = f\"{BASE_DIR}/{task}_val.csv\"\n",
    "        class_path = f\"{BASE_DIR}/{task}_class.txt\"\n",
    "\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"Exploring {task.upper()} dataset\")\n",
    "        print(f\"{'='*40}\")\n",
    "\n",
    "        print(f\"Train file exists: {os.path.exists(train_path)}\")\n",
    "        print(f\"Val file exists: {os.path.exists(val_path)}\")\n",
    "        print(f\"Class file exists: {os.path.exists(class_path)}\")\n",
    "\n",
    "        try:\n",
    "            train_df = pd.read_csv(train_path)  \n",
    "            val_df = pd.read_csv(val_path)      \n",
    "\n",
    "            print(f\"\\nTrain data shape: {train_df.shape}\")\n",
    "            print(f\"Validation data shape: {val_df.shape}\")\n",
    "\n",
    "            print(f\"\\nTrain columns: {train_df.columns.tolist()}\")\n",
    "\n",
    "            print(\"\\nSample train data (first 3 rows):\")\n",
    "            print(train_df.head(3))\n",
    "\n",
    "            if len(train_df.columns) >= 2:\n",
    "                label_col = train_df.iloc[:, 1] \n",
    "                unique_labels = label_col.unique()\n",
    "                print(f\"\\nNumber of unique labels in training data: {len(unique_labels)}\")\n",
    "                print(f\"Sample labels: {unique_labels[:5].tolist()}\")\n",
    "\n",
    "            if len(train_df.columns) >= 1:\n",
    "                img_col = train_df.iloc[:, 0] \n",
    "                sample_paths = img_col.sample(min(3, len(img_col))).tolist()\n",
    "                print(\"\\nSample image paths:\")\n",
    "                for path in sample_paths:\n",
    "                    print(f\"  {path}\")\n",
    "                    full_path = os.path.join(WIKIART_DIR, path)\n",
    "                    print(f\"  Exists in wikiart folder: {os.path.exists(full_path)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error exploring {task} dataset: {str(e)}\")\n",
    "\n",
    "print(\"Exploring dataset structure...\")\n",
    "explore_dataset()\n",
    "\n",
    "print(\"\\nStarting model training...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "94a7670f-05c3-4447-8a6f-aecf645f11ce",
   "metadata": {
    "id": "94a7670f-05c3-4447-8a6f-aecf645f11ce"
   },
   "outputs": [],
   "source": [
    "def train_model(task, subset_size=1.0):\n",
    "    \"\"\"Train the improved model with enhanced training strategy.\"\"\"\n",
    "    train_df = load_data(f\"{BASE_DIR}/{task}_train.csv\", subset_size=subset_size)\n",
    "    val_df = load_data(f\"{BASE_DIR}/{task}_val.csv\", subset_size=subset_size)\n",
    "    classes = load_classes(f\"{BASE_DIR}/{task}_class.txt\")\n",
    "\n",
    "    train_df, val_df, label_encoder, class_weights_dict = preprocess_data(train_df, val_df, classes)\n",
    "\n",
    "    train_dataset = create_data_generators(train_df, BATCH_SIZE, task)\n",
    "    val_dataset = create_data_generators(val_df, BATCH_SIZE, task)\n",
    "\n",
    "    model = build_conv_recurrent_model(len(classes), task)\n",
    "    print(model.summary())\n",
    "\n",
    "    # Callbacks for better training\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        f'{MODELS_DIR}/models/best_model_{task}.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=12,  \n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,  \n",
    "        patience=4,  \n",
    "        min_lr=1e-7,  \n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE, weight_decay=1e-6),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    print(\"Phase 1: Initial training with mostly frozen base model...\")\n",
    "    history1 = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=[checkpoint, early_stopping, reduce_lr],\n",
    "        class_weight=class_weights_dict\n",
    "    )\n",
    "\n",
    "    print(\"Phase 2: Fine-tuning with more layers unfrozen...\")\n",
    "    base_model = model.layers[1]\n",
    "\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE/10, weight_decay=1e-6), \n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    history2 = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=10,  \n",
    "        initial_epoch=history1.epoch[-1] + 1,\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=[checkpoint, early_stopping, reduce_lr],\n",
    "        class_weight=class_weights_dict\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"Evaluating model...\")\n",
    "    outlier_indices, predictions, true_classes, predicted_classes = evaluate_model(\n",
    "        model, val_dataset, label_encoder,task\n",
    "    )\n",
    "\n",
    "    print(\"Visualizing results...\")\n",
    "    combined_history = {}\n",
    "    for k in history1.history.keys():\n",
    "        combined_history[k] = history1.history[k] + history2.history[k]\n",
    "\n",
    "    visualize_training_history(combined_history,task)\n",
    "    visualize_outliers(\n",
    "        outlier_indices, val_dataset, predictions,\n",
    "        true_classes, predicted_classes, label_encoder,task\n",
    "    )\n",
    "\n",
    "    return model, combined_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9fa415-afca-49f1-9cce-93923562e70b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bf9fa415-afca-49f1-9cce-93923562e70b",
    "outputId": "10b22923-32a5-4571-c67f-d71e6d4ccb88"
   },
   "outputs": [],
   "source": [
    "def train_all_models_improved():\n",
    "    \"\"\"Train improved models for all tasks with stratified sampling.\"\"\"\n",
    "    results = {}\n",
    "    subset_sizes = {\n",
    "        \"artist\": 1.0,  # Use 100% of the dataset for Artist\n",
    "        \"genre\": 0.5,   # Use 50% of the dataset for Genre\n",
    "        \"style\": 0.3    # Use 30% of the dataset for Style\n",
    "    }\n",
    "\n",
    "    for task in [\"artist\"]:\n",
    "        print(f\"\\n\\n{'='*60}\")\n",
    "        print(f\"Training improved model for {task.upper()}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "        model, history = train_model(task, subset_size=subset_sizes[task])\n",
    "        results[task] = (model, history)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Training all models\n",
    "    all_results = train_all_models_improved()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "25ff8987-bb6c-4ff1-a060-46355d91e5b8",
   "metadata": {
    "id": "25ff8987-bb6c-4ff1-a060-46355d91e5b8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "45adf9f2-8c8b-4546-bee3-50c1f0023e42",
   "metadata": {
    "id": "45adf9f2-8c8b-4546-bee3-50c1f0023e42"
   },
   "outputs": [],
   "source": [
    "def load_trained_model(task):\n",
    "    \"\"\"Load a trained model for a specific task\"\"\"\n",
    "    model_path = f'{MODELS_DIR}/models/best_model_{task}.keras'\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Error: Model for {task} not found at {model_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        model = load_model(model_path)\n",
    "        print(f\"Successfully loaded {task} model\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {task} model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_class_labels(task):\n",
    "    \"\"\"Load class labels for a specific task\"\"\"\n",
    "    classes_path = f'{BASE_DIR}/{task}_class.txt'\n",
    "    try:\n",
    "        with open(classes_path, 'r') as f:\n",
    "            classes = [line.strip() for line in f.readlines()]\n",
    "        print(f\"Loaded {len(classes)} {task} classes\")\n",
    "        return classes\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {task} classes: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0fd9612d-791a-4fea-baad-fd69c4c323f2",
   "metadata": {
    "id": "0fd9612d-791a-4fea-baad-fd69c4c323f2"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    \"\"\"Preprocess an image for model prediction\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Error: Image not found at {img_path}\")\n",
    "            return None\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = img_array / 255.0  \n",
    "\n",
    "        return img_array, img\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing image: {str(e)}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0f49594a-780a-4a57-b813-a50fca2b2bea",
   "metadata": {
    "id": "0f49594a-780a-4a57-b813-a50fca2b2bea"
   },
   "outputs": [],
   "source": [
    "def predict_artwork(img_path, tasks=None):\n",
    "    \"\"\"\n",
    "    Predict artist, style, and genre for a given artwork image\n",
    "\n",
    "    Parameters:\n",
    "    img_path (str): Path to the artwork image\n",
    "    tasks (list): List of tasks to perform, default [\"artist\", \"genre\", \"style\"]\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with predictions for each task\n",
    "    \"\"\"\n",
    "    if tasks is None:\n",
    "        tasks = [\"artist\", \"genre\", \"style\"]\n",
    "\n",
    "    img_array, original_img = preprocess_image(img_path)\n",
    "    if img_array is None:\n",
    "        return None\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    models = {task: load_trained_model(task) for task in tasks}\n",
    "    class_labels = {task: load_class_labels(task) for task in tasks}\n",
    "\n",
    "    for task in tasks:\n",
    "        print(f\"\\nPredicting {task}...\")\n",
    "\n",
    "        model = models.get(task)\n",
    "        classes = class_labels.get(task)\n",
    "\n",
    "        if model is None or classes is None:\n",
    "            results[task] = {\"error\": f\"Could not load model or classes for {task}\"}\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img_tensor = tf.convert_to_tensor(img_array)\n",
    "            img_tensor = tf.ensure_shape(img_tensor, (1, 224, 224, 3))  # Example shape (adjust to your model)\n",
    "\n",
    "            @tf.function(reduce_retracing=True)\n",
    "            def predict_step(input_tensor):\n",
    "                return model(input_tensor)\n",
    "\n",
    "            predictions = predict_step(img_tensor)\n",
    "\n",
    "            top_indices = tf.argsort(predictions[0], direction=\"DESCENDING\")[:3]\n",
    "            top_predictions = [(classes[i.numpy()], float(predictions[0][i].numpy())) for i in top_indices]\n",
    "\n",
    "            results[task] = {\n",
    "                \"top_predictions\": top_predictions,\n",
    "                \"prediction\": classes[int(tf.argmax(predictions[0]))],\n",
    "                \"confidence\": float(tf.reduce_max(predictions[0]))\n",
    "            }\n",
    "\n",
    "            print(f\"Top {task} predictions:\")\n",
    "            for class_name, prob in top_predictions:\n",
    "                print(f\"  {class_name}: {prob:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error making prediction for {task}: {str(e)}\")\n",
    "            results[task] = {\"error\": str(e)}\n",
    "\n",
    "    visualize_prediction_results(img_path, original_img, results)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e6981cef-7219-46d8-ba9d-2eba5bf30e03",
   "metadata": {
    "id": "e6981cef-7219-46d8-ba9d-2eba5bf30e03"
   },
   "outputs": [],
   "source": [
    "def visualize_prediction_results(img_path, original_img, results):\n",
    "    \"\"\"Visualize the prediction results\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(original_img)\n",
    "    plt.title(f\"Artwork: {os.path.basename(img_path)}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.axis('off')\n",
    "\n",
    "    result_text = \"Prediction Results:\\n\\n\"\n",
    "\n",
    "    for task in results:\n",
    "        result_text += f\"{task.capitalize()}:\\n\"\n",
    "\n",
    "        if \"error\" in results[task]:\n",
    "            result_text += f\"  Error: {results[task]['error']}\\n\"\n",
    "        else:\n",
    "            for i, (class_name, prob) in enumerate(results[task][\"top_predictions\"]):\n",
    "                result_text += f\"  {i+1}. {class_name}: {prob:.2%}\\n\"\n",
    "\n",
    "        result_text += \"\\n\"\n",
    "\n",
    "    plt.text(0.1, 0.5, result_text, fontsize=12, verticalalignment='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('artwork_prediction.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b2ce6a14-365a-4956-94b2-4e80c94d2cb4",
   "metadata": {
    "id": "b2ce6a14-365a-4956-94b2-4e80c94d2cb4"
   },
   "outputs": [],
   "source": [
    "def batch_predict_artworks(folder_path, tasks=None):\n",
    "    \"\"\"\n",
    "    Predict artist, style, and genre for all artwork images in a folder\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): Path to the folder containing artwork images\n",
    "    tasks (list): List of tasks to perform, default [\"artist\", \"genre\", \"style\"]\n",
    "    \"\"\"\n",
    "    if tasks is None:\n",
    "        tasks = [\"artist\", \"genre\", \"style\"]\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Error: Folder not found at {folder_path}\")\n",
    "        return\n",
    "\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png']\n",
    "    image_files = [f for f in os.listdir(folder_path)\n",
    "                  if os.path.isfile(os.path.join(folder_path, f)) and\n",
    "                  any(f.lower().endswith(ext) for ext in image_extensions)]\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No image files found in {folder_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(image_files)} image files. Starting batch prediction...\")\n",
    "\n",
    "    models = {}\n",
    "    class_labels = {}\n",
    "\n",
    "    for task in tasks:\n",
    "        models[task] = load_trained_model(task)\n",
    "        class_labels[task] = load_class_labels(task)\n",
    "\n",
    "        if models[task] is None or class_labels[task] is None:\n",
    "            print(f\"Warning: Could not load model or classes for {task}\")\n",
    "\n",
    "    all_results = {}\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(folder_path, img_file)\n",
    "        print(f\"\\nProcessing {img_file}...\")\n",
    "\n",
    "        img_array, _ = preprocess_image(img_path)\n",
    "        if img_array is None:\n",
    "            all_results[img_file] = {\"error\": \"Failed to preprocess image\"}\n",
    "            continue\n",
    "\n",
    "        img_results = {}\n",
    "        for task in tasks:\n",
    "            if models[task] is None or class_labels[task] is None:\n",
    "                img_results[task] = {\"error\": f\"Model or classes not available for {task}\"}\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                predictions = models[task].predict(img_array)\n",
    "\n",
    "                top_indices = np.argsort(predictions[0])[-3:][::-1]\n",
    "                top_predictions = [(class_labels[task][i], float(predictions[0][i])) for i in top_indices]\n",
    "\n",
    "                img_results[task] = {\n",
    "                    \"top_predictions\": top_predictions,\n",
    "                    \"prediction\": class_labels[task][np.argmax(predictions)],\n",
    "                    \"confidence\": float(np.max(predictions))\n",
    "                }\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error making {task} prediction for {img_file}: {str(e)}\")\n",
    "                img_results[task] = {\"error\": str(e)}\n",
    "\n",
    "        all_results[img_file] = img_results\n",
    "\n",
    "    export_results_to_csv(all_results, folder_path)\n",
    "\n",
    "    print(f\"\\nCompleted batch prediction for {len(image_files)} images\")\n",
    "    return all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4912ab3a-9b07-4d7d-b4cc-b64cce522b13",
   "metadata": {
    "id": "4912ab3a-9b07-4d7d-b4cc-b64cce522b13"
   },
   "outputs": [],
   "source": [
    "def export_results_to_csv(all_results, folder_path):\n",
    "    \"\"\"Export batch prediction results to CSV\"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    rows = []\n",
    "    for img_file, img_results in all_results.items():\n",
    "        row = {'image': img_file}\n",
    "\n",
    "        for task in img_results:\n",
    "            if \"error\" in img_results[task]:\n",
    "                row[f'{task}_prediction'] = \"ERROR\"\n",
    "                row[f'{task}_confidence'] = 0.0\n",
    "            else:\n",
    "                row[f'{task}_prediction'] = img_results[task][\"prediction\"]\n",
    "                row[f'{task}_confidence'] = img_results[task][\"confidence\"]\n",
    "\n",
    "                # Add top 3 predictions\n",
    "                for i, (class_name, prob) in enumerate(img_results[task][\"top_predictions\"]):\n",
    "                    row[f'{task}_top{i+1}'] = class_name\n",
    "                    row[f'{task}_top{i+1}_confidence'] = prob\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    csv_path = os.path.join(folder_path, 'artwork_predictions.csv')\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Results exported to {csv_path}\")\n",
    "\n",
    "def analyze_single_image(img_path):\n",
    "    \"\"\"\n",
    "    Analyze a single artwork image for artist, style, and genre\n",
    "\n",
    "    Parameters:\n",
    "    img_path (str): Path to the artwork image\n",
    "    \"\"\"\n",
    "    print(f\"Analyzing artwork: {img_path}\")\n",
    "    results = predict_artwork(img_path)\n",
    "\n",
    "    if results:\n",
    "        print(\"\\nSummary of predictions:\")\n",
    "        for task, task_results in results.items():\n",
    "            if \"error\" in task_results:\n",
    "                print(f\"  {task.capitalize()}: Error - {task_results['error']}\")\n",
    "            else:\n",
    "                print(f\"  {task.capitalize()}: {task_results['prediction']} ({task_results['confidence']:.2%})\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f7302e-8d9d-4074-9d66-43b8e5ea3005",
   "metadata": {
    "id": "c4f7302e-8d9d-4074-9d66-43b8e5ea3005",
    "outputId": "efd76fbb-c555-4b2c-eca9-c6b5e4c2014a"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Single image prediction\n",
    "    print(\"\\n===== Single Image Prediction =====\")\n",
    "    analyze_single_image(test_image_path)\n",
    "\n",
    "    # Batch prediction example - uncomment to use\n",
    "    # test_folder_path = \"./test_images\"  # Change this to your test folder path\n",
    "    # print(\"\\n===== Batch Prediction =====\")\n",
    "    # batch_results = batch_predict_artworks(test_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93387b1-b6f3-4db2-ae39-706613952509",
   "metadata": {
    "id": "d93387b1-b6f3-4db2-ae39-706613952509"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
